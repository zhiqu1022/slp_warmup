{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883a7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# function of read data\n",
    "def _read_txt_(url):\n",
    "    file = open(url, 'r', encoding='utf-8')\n",
    "    seg_list = []\n",
    "    lines = file.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        seg_list.append(lines[i].rstrip(\"\\n\").split('\\t'))\n",
    "        pass\n",
    "    file.close()\n",
    "    return seg_list\n",
    "\n",
    "# replace Capital word with <Capital>\n",
    "# replace SUPPER word with <SUPPER>\n",
    "# replace digit word, like 1997, with <digit>\n",
    "# replace connect-word word with <connect>\n",
    "def _clean_data_(data):\n",
    "    list_idx_remove = []\n",
    "    for idx, x in enumerate(data):\n",
    "        # ignore label\n",
    "        words = x[1].split(\" \")\n",
    "        words.insert(0, \"<s>\")\n",
    "        words.append(\"<\\s>\")\n",
    "        for i, word in enumerate(words):\n",
    "            if word.isupper():\n",
    "                words[i] = \"<SUPPER>\"\n",
    "                continue\n",
    "            if word.istitle():\n",
    "                words[i] = \"<Capital>\"\n",
    "                continue\n",
    "            if word.isdigit():\n",
    "                words[i] = \"<digit>\"\n",
    "                continue\n",
    "            if len(word) > 1 and word.find(\"-\") != -1:\n",
    "                words[i] = \"<connect>\"\n",
    "        data[idx][1] = words \n",
    "    return data\n",
    "# define unique word list\n",
    "# This dict is for the test set to define unk\n",
    "# simply speaking, the word not in this dict, and frequency < 2 should be defined as unk.\n",
    "def _unique_list_(data):\n",
    "    unique_word_frequency = {}\n",
    "    for _, x in enumerate(data):\n",
    "        words = x[1]\n",
    "        for _, word in enumerate(words):\n",
    "            if word not in unique_word_frequency:\n",
    "                unique_word_frequency[word] = 1\n",
    "            else:\n",
    "                num = unique_word_frequency[word]\n",
    "                unique_word_frequency[word] = num + 1\n",
    "    return unique_word_frequency\n",
    "\n",
    "# replace word whose frequency < 2 with <UNK>\n",
    "def _UNK_(data, refer_dict):\n",
    "    for idx, x in enumerate(data):\n",
    "        words = x[1]\n",
    "        for i, word in enumerate(words):\n",
    "            if refer_dict[word] < 2:\n",
    "                words[i] = \"<UNK>\"\n",
    "        data[idx][1] = words\n",
    "    return data\n",
    "            \n",
    "train_list = _read_txt_(\"titles-en-train.labeled\")\n",
    "train_list = _clean_data_(train_list)\n",
    "unique_word_frequency = _unique_list_(train_list)\n",
    "train_list = _UNK_(train_list, unique_word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49be887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize perceptron\n",
    "# feature is 3-gram\n",
    "N = 3\n",
    "weight_dict = {}\n",
    "# initialize weight_dict\n",
    "file_name = \"perceptron_3_gram_initial.npy\"\n",
    "if os.path.exists(file_name):\n",
    "    weight_dict = np.load(file_name,allow_pickle=True).item()\n",
    "else:\n",
    "    for _, x in enumerate(train_list):\n",
    "        words = x[1]\n",
    "        for i in range(len(words)):\n",
    "            if (i + N) >= len(words) + 1: continue\n",
    "            windows = words[i:i+N]\n",
    "            combination = \"\"\n",
    "            for j in range(N):\n",
    "                if j == 0:\n",
    "                    combination += windows[j]\n",
    "                else:\n",
    "                    combination += \"|\" + windows[j]\n",
    "            if combination not in weight_dict:\n",
    "                weight_dict[combination] = 0\n",
    "    np.save(file_name, weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa52070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train perceptron\n",
    "# feature is 3-gram\n",
    "N = 3\n",
    "# weight_dict = {}\n",
    "# train\n",
    "file_name = \"perceptron_3_gram_trained.npy\"\n",
    "if os.path.exists(file_name):\n",
    "    weight_dict = np.load(file_name,allow_pickle=True).item()\n",
    "else:\n",
    "    for idx, x in enumerate(train_list):\n",
    "        label = int(x[0])\n",
    "        words = x[1]\n",
    "        for i in range(len(words)):\n",
    "            if (i + N) >= len(words) + 1: continue\n",
    "            windows = words[i:i+N]\n",
    "            combination = \"\"\n",
    "            for j in range(N):\n",
    "                if j == 0:\n",
    "                    combination += windows[j]\n",
    "                else:\n",
    "                    combination += \"|\" + windows[j]\n",
    "            num = weight_dict[combination]\n",
    "            weight_dict[combination] = num + label\n",
    "    np.save(file_name, weight_dict)\n",
    "    \n",
    "# log scaling (standardization)\n",
    "import math\n",
    "for key in weight_dict.keys():\n",
    "    num = weight_dict[key]\n",
    "    if num > 0:\n",
    "        weight_dict[key] = math.log10(num)\n",
    "    if num < 0:\n",
    "        weight_dict[key] = -math.log10(abs(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc55826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 91.4%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_list = _read_txt_(\"titles-en-test.labeled\")\n",
    "test_list = _clean_data_(test_list)\n",
    "for idx, x in enumerate(test_list):\n",
    "    words = x[1]\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in unique_word_frequency:\n",
    "            words[i] = \"<UNK>\"\n",
    "    test_list[idx][1] = words\n",
    "    \n",
    "total = len(test_list)\n",
    "correct = 0\n",
    "incorrect_idx_list = []\n",
    "for idx, x in enumerate(test_list):\n",
    "    label = int(x[0])\n",
    "    words = x[1]\n",
    "    scores = 0\n",
    "    for i in range(len(words)):\n",
    "        if (i + N) >= len(words) + 1: continue\n",
    "        windows = words[i:i+N]\n",
    "        combination = \"\"\n",
    "        for j in range(N):\n",
    "            if j == 0:\n",
    "                combination += windows[j]\n",
    "            else:\n",
    "                combination += \"|\" + windows[j]\n",
    "        if combination in weight_dict:\n",
    "            scores += weight_dict[combination]\n",
    "        else:\n",
    "            scores += -1\n",
    "    if label == 1:\n",
    "        if scores > 0:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect_idx_list.append(idx)\n",
    "    else:\n",
    "        if scores <= 0:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect_idx_list.append(idx)\n",
    "            \n",
    "print(\"acc: \" + str(round(correct/total,3)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eca5b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 12, 13, 18, 29, 41, 42, 44]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_idx_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312bdf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " ['<s>',\n",
       "  '<Capital>',\n",
       "  '(',\n",
       "  'also',\n",
       "  'called',\n",
       "  '<Capital>',\n",
       "  ')',\n",
       "  'means',\n",
       "  'a',\n",
       "  'person',\n",
       "  'who',\n",
       "  'was',\n",
       "  'the',\n",
       "  'biological',\n",
       "  'mother',\n",
       "  'of',\n",
       "  'an',\n",
       "  '<Capital>',\n",
       "  'and',\n",
       "  'consort',\n",
       "  'of',\n",
       "  'the',\n",
       "  'previous',\n",
       "  '<Capital>',\n",
       "  '.',\n",
       "  '<\\\\s>']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65df3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
