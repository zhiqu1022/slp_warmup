{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e938910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "10\n",
      "11\n",
      "13\n",
      "38\n",
      "46\n",
      "74\n",
      "113\n",
      "139\n",
      "145\n",
      "169\n",
      "9.491503869427241\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "# define N-gram\n",
    "N = 3\n",
    "# define hyperparameter of knears smoothing\n",
    "d = 0.75\n",
    "lambda_unk = 0.05\n",
    "def _total_num_words(data):\n",
    "    num = 0\n",
    "    for _, seq in enumerate(data):\n",
    "        words = seq.split(\" \")\n",
    "        num += len(words)\n",
    "    return num\n",
    "    \n",
    "# function of read data\n",
    "def _read_txt_(url):\n",
    "    file = open(url, 'r', encoding='utf-8')\n",
    "    seg_list = []\n",
    "    lines = file.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        seg_list.append(\"<s> \" + lines[i].rstrip(\"\\n\") + \" </s>\")\n",
    "        pass\n",
    "    file.close()\n",
    "    return seg_list\n",
    "\n",
    "train_list = _read_txt_(\"wiki-en-train.word\")\n",
    "\n",
    "# basic function to count n-gram (windows) frequency\n",
    "def _count_N_(data, n=1):\n",
    "    tmp_dict = {}\n",
    "    for _, seq in enumerate(data):\n",
    "        words = seq.split(\" \")\n",
    "        for i in range(len(words)):\n",
    "            if (i + n) >= len(words) + 1: continue\n",
    "            windows = words[i:i+n]\n",
    "            combination = \"\"\n",
    "            for j in range(n):\n",
    "                if j == 0:\n",
    "                    combination += windows[j]\n",
    "                else:\n",
    "                    combination += \"|\" + windows[j]\n",
    "            if combination not in tmp_dict:\n",
    "                tmp_dict[combination] = 1\n",
    "            else:\n",
    "                num = tmp_dict[combination]\n",
    "                tmp_dict[combination] = num + 1\n",
    "    np.save(\"{}_count_dict\".format(str(n)), tmp_dict)\n",
    "    return tmp_dict\n",
    "\n",
    "# count unique word frequency\n",
    "count_set = {}\n",
    "for i in range(N):\n",
    "    n = i + 1\n",
    "    file_name = \"{}_count_dict.npy\".format(str(n))\n",
    "    if os.path.exists(file_name):\n",
    "        count_set[str(n)] = np.load(file_name,allow_pickle=True).item()\n",
    "    else:\n",
    "        count_set[str(n)] = _count_N_(train_list,n)\n",
    "\n",
    "        \n",
    "# Witten-Bell Smoothing to confirm the lambda of each element\n",
    "lambda_dict = {}\n",
    "file_name = \"{}_lambda_dict.npy\".format(str(N))\n",
    "if os.path.exists(file_name):\n",
    "    lambda_dict = np.load(file_name,allow_pickle=True).item()\n",
    "else:\n",
    "    tmp_count = list(count_set[str(N-1)].keys())\n",
    "    tmp_count_current = list(count_set[str(N)].keys())\n",
    "    unique_set = {}\n",
    "    for _, x in enumerate(tmp_count):\n",
    "        num = 0\n",
    "        for _,y in enumerate(tmp_count_current):\n",
    "            if y.startswith(x+\"|\"):\n",
    "                num += 1\n",
    "        unique_set[x] = num\n",
    "    for idx, x in enumerate(tmp_count):\n",
    "        lambda_dict[x] = 1 - (unique_set[x]/(unique_set[x] + count_set[str(N-1)][x]))\n",
    "    np.save(file_name, lambda_dict)\n",
    "\n",
    "# p_continuation\n",
    "# key: N-1 gram ; Value: list[N-gram with same N-1 gram]\n",
    "count_continuation = {}\n",
    "file_name = \"{}_continuation_dict.npy\".format(str(N))\n",
    "if os.path.exists(file_name):\n",
    "    count_continuation = np.load(file_name,allow_pickle=True).item()\n",
    "else:\n",
    "    tmp_count = list(count_set[str(N-1)].keys())\n",
    "    tmp_count_current = list(count_set[str(N)].keys())\n",
    "    for idx, x in enumerate(tmp_count):\n",
    "        list_tmp = []\n",
    "        for _, y in enumerate(tmp_count_current):\n",
    "            if y.startswith(x+\"|\"):\n",
    "                list_tmp.append(y)\n",
    "        count_continuation[x] = list_tmp\n",
    "    np.save(\"{}_continuation_dict.npy\".format(str(N)), count_continuation)\n",
    "\n",
    "# P_kn = p_kn + P_continuation\n",
    "# p_kn = max(count(N_gram) - d, 0)/count(N-1_gram)\n",
    "# P_continuation = lambda * p_continuation\n",
    "# lambda: d/ count(N-1_gram) * count(N_gram)\n",
    "# p_continuation: count(N_gram) / sum of count(N_gram) with same N-1 gram, that is sum (vw') by w'\n",
    "def _compute_p_kn_(words):\n",
    "    \n",
    "    prefix = words[0]\n",
    "    for idx, x in enumerate(words[1:-1]):\n",
    "        prefix =  prefix + \"|\" + x\n",
    "    windows = prefix + \"|\" + words[len(words) - 1]\n",
    "    tmp_count = count_set[str(N-1)]\n",
    "    tmp_count_current = count_set[str(N)]\n",
    "    same_prefix_list = count_continuation[prefix]\n",
    "    \n",
    "    value = tmp_count_current[windows] - d\n",
    "    denominator = 0\n",
    "    for x in same_prefix_list:\n",
    "        denominator = denominator + tmp_count_current[x]\n",
    "    numerator = tmp_count_current[windows]\n",
    "    if numerator > 0:\n",
    "        return value/tmp_count[prefix] + (d / tmp_count[prefix]) * tmp_count_current[windows] * (numerator/denominator)\n",
    "    else:\n",
    "        return (d / tmp_count[prefix]) * tmp_count_current[windows] * (numerator/denominator)\n",
    "def _p_(sentence, n=1, T=1):\n",
    "    words = sentence.split(\" \")\n",
    "    keys_count_current = list(count_set[str(N)].keys())\n",
    "    lambda_unk = 0.05\n",
    "    p = 0\n",
    "    for i in range(len(words)):\n",
    "#         print(p)\n",
    "        if (i + n) >= len(words) + 1: continue\n",
    "        windows = words[i:i+n]\n",
    "        combination = \"\"\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                combination += windows[j]\n",
    "            else:\n",
    "                combination += \"|\" + windows[j]\n",
    "        if combination not in keys_count_current:\n",
    "            # this word is unknown\n",
    "            if p == 0:\n",
    "                    # the first window\n",
    "                p = lambda_unk * (1 / T)\n",
    "            else:\n",
    "                p = p * lambda_unk * (1 / T)\n",
    "        else:\n",
    "            if p == 0:\n",
    "                p = _compute_p_kn_(windows)\n",
    "            else:\n",
    "                p = p * _compute_p_kn_(windows)\n",
    "    return -math.log(p)\n",
    "\n",
    "test_list = _read_txt_(\"wiki-en-test.word\")\n",
    "P_total = 0\n",
    "T_test = _total_num_words(test_list)\n",
    "for idx, x in enumerate(test_list):\n",
    "    p = _p_(x, N, T_test)\n",
    "    if p > 500:\n",
    "        print(idx)\n",
    "    P_total = P_total + p\n",
    "print(P_total/T_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
